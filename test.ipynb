{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import torch\n",
    "# from torch_geometric.data import Data\n",
    "# import json\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from helper import load_twitch_dataset, prepare_GNN_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Source', 'Target'], dtype='object')\n",
      "   Source  Target\n",
      "0    6194     255\n",
      "1    6194     980\n",
      "2    6194    2992\n",
      "3    6194    2507\n",
      "4    6194     986\n",
      "Data(edge_index=[2, 35324])\n",
      "Data(edge_index=[2, 35324], x=[7126, 3170])\n",
      "Data(edge_index=[2, 35324], x=[7126, 3170], y=[7126])\n",
      "Data(edge_index=[2, 35324], x=[7126, 3170], y=[7126])\n"
     ]
    }
   ],
   "source": [
    "data = load_twitch_dataset()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 35324], x=[7126, 3170], y=[7126], train_mask=[7126], val_mask=[7126], test_mask=[7126])\n",
      "Data(edge_index=[2, 35324], x=[7126, 3170], y=[7126], train_mask=[7126], val_mask=[7126], test_mask=[7126])\n"
     ]
    }
   ],
   "source": [
    "data = prepare_GNN_data(data)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Source', 'Target'], dtype='object')\n",
      "   Source  Target\n",
      "0    6194     255\n",
      "1    6194     980\n",
      "2    6194    2992\n",
      "3    6194    2507\n",
      "4    6194     986\n",
      "Data(edge_index=[2, 35324])\n"
     ]
    }
   ],
   "source": [
    "# Load edges file\n",
    "edges = pd.read_csv('./twitch/ENGB/musae_ENGB_edges_edited.csv', sep=',')\n",
    "# print(edges)\n",
    "\n",
    "print(edges.columns)\n",
    "print(edges.head())\n",
    "\n",
    "# Ensure columns are integers\n",
    "edges['Source'] = pd.to_numeric(edges['Source'], errors='coerce').fillna(0).astype(int)\n",
    "edges['Target'] = pd.to_numeric(edges['Target'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "# Convert to edge index tensor\n",
    "edge_index = torch.tensor(edges[['Source', 'Target']].values.T, dtype=torch.long)\n",
    "\n",
    "# Create graph data object\n",
    "data = Data(edge_index=edge_index)\n",
    "print(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 35324], x=[7126, 3170])\n"
     ]
    }
   ],
   "source": [
    "# Load node features\n",
    "with open('./twitch/ENGB/musae_ENGB_features.json') as f:\n",
    "    features = json.load(f)\n",
    "\n",
    "# Convert features to a matrix\n",
    "node_features = np.zeros((len(features), max(max(f) for f in features.values()) + 1))\n",
    "for node, feats in features.items():\n",
    "    node_features[int(node), feats] = 1  # One-hot encoding of features\n",
    "\n",
    "# Convert to tensor\n",
    "x = torch.tensor(node_features, dtype=torch.float)\n",
    "data.x = x\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 35324], x=[7126, 3170], y=[7126])\n"
     ]
    }
   ],
   "source": [
    "# Load target file\n",
    "target = pd.read_csv('./twitch/ENGB/musae_ENGB_target_edited.csv')\n",
    "\n",
    "# Create label tensor\n",
    "labels = target['mature'].astype(int).values\n",
    "y = torch.tensor(labels, dtype=torch.long)\n",
    "data.y = y\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 35324], x=[7126, 3170], y=[7126], train_mask=[7126], val_mask=[7126], test_mask=[7126])\n"
     ]
    }
   ],
   "source": [
    "# Split indices for training, validation, and testing\n",
    "train_idx, test_idx = train_test_split(range(len(labels)), test_size=0.3, stratify=labels)\n",
    "val_idx, test_idx = train_test_split(test_idx, test_size=0.5, stratify=labels[test_idx])\n",
    "\n",
    "# Convert to tensors\n",
    "train_mask = torch.zeros(len(labels), dtype=torch.bool)\n",
    "val_mask = torch.zeros(len(labels), dtype=torch.bool)\n",
    "test_mask = torch.zeros(len(labels), dtype=torch.bool)\n",
    "\n",
    "train_mask[train_idx] = True\n",
    "val_mask[val_idx] = True\n",
    "test_mask[test_idx] = True\n",
    "\n",
    "data.train_mask = train_mask\n",
    "data.val_mask = val_mask\n",
    "data.test_mask = test_mask\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.x.shape)  # Should be [num_nodes, num_features]\n",
    "print(data.edge_index.shape)  # Should be [2, num_edges]\n",
    "print(data.y.shape)  # Should be [num_nodes]\n",
    "print(f\"Train nodes: {data.train_mask.sum().item()}, Validation nodes: {data.val_mask.sum().item()}, Test nodes: {data.test_mask.sum().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.6941, Train Acc: 0.5457, Val Acc: 0.5463\n",
      "Epoch 10, Loss: 0.6670, Train Acc: 0.6153, Val Acc: 0.5304\n",
      "Epoch 20, Loss: 0.6263, Train Acc: 0.6534, Val Acc: 0.5295\n",
      "Epoch 30, Loss: 0.5888, Train Acc: 0.6824, Val Acc: 0.5398\n",
      "Epoch 40, Loss: 0.5647, Train Acc: 0.6981, Val Acc: 0.5313\n",
      "Epoch 50, Loss: 0.5462, Train Acc: 0.7093, Val Acc: 0.5267\n",
      "Epoch 60, Loss: 0.5288, Train Acc: 0.7310, Val Acc: 0.5220\n",
      "Epoch 70, Loss: 0.5123, Train Acc: 0.7428, Val Acc: 0.5220\n",
      "Epoch 80, Loss: 0.4942, Train Acc: 0.7586, Val Acc: 0.5201\n",
      "Epoch 90, Loss: 0.4763, Train Acc: 0.7704, Val Acc: 0.5267\n",
      "Epoch 100, Loss: 0.4633, Train Acc: 0.7759, Val Acc: 0.5313\n",
      "Epoch 110, Loss: 0.4510, Train Acc: 0.7911, Val Acc: 0.5295\n",
      "Epoch 120, Loss: 0.4376, Train Acc: 0.7983, Val Acc: 0.5285\n",
      "Epoch 130, Loss: 0.4246, Train Acc: 0.8152, Val Acc: 0.5192\n",
      "Epoch 140, Loss: 0.4157, Train Acc: 0.8256, Val Acc: 0.5201\n",
      "Epoch 150, Loss: 0.4120, Train Acc: 0.8326, Val Acc: 0.5145\n",
      "Epoch 160, Loss: 0.4003, Train Acc: 0.8350, Val Acc: 0.5117\n",
      "Epoch 170, Loss: 0.3975, Train Acc: 0.8430, Val Acc: 0.5108\n",
      "Epoch 180, Loss: 0.3897, Train Acc: 0.8480, Val Acc: 0.5061\n",
      "Epoch 190, Loss: 0.3788, Train Acc: 0.8528, Val Acc: 0.5070\n",
      "Test Accuracy: 0.4874\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "# Define the GCN model\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Initialize the model, optimizer, and loss function\n",
    "input_dim = data.x.shape[1]\n",
    "hidden_dim = 16\n",
    "output_dim = 2  # Binary classification (mature or not)\n",
    "model_gcn = GCN(input_dim, hidden_dim, output_dim)\n",
    "optimizer = torch.optim.Adam(model_gcn.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "# Training function\n",
    "def train():\n",
    "    model_gcn.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model_gcn(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(mask):\n",
    "    model_gcn.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model_gcn(data)\n",
    "        pred = out[mask].max(1)[1]\n",
    "        acc = (pred == data.y[mask]).sum().item() / mask.sum().item()\n",
    "    return acc\n",
    "\n",
    "# Train and evaluate the model\n",
    "for epoch in range(200):\n",
    "    loss = train()\n",
    "    if epoch % 10 == 0:\n",
    "        train_acc = evaluate(data.train_mask)\n",
    "        val_acc = evaluate(data.val_mask)\n",
    "        print(f'Epoch {epoch}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}')\n",
    "\n",
    "# Test the model\n",
    "test_acc = evaluate(data.test_mask)\n",
    "print(f'Test Accuracy: {test_acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.7120, Train Acc: 0.5463, Val Acc: 0.5519\n",
      "Epoch 10, Loss: 0.6441, Train Acc: 0.5932, Val Acc: 0.5585\n",
      "Epoch 20, Loss: 0.5802, Train Acc: 0.6995, Val Acc: 0.5323\n",
      "Epoch 30, Loss: 0.5175, Train Acc: 0.7833, Val Acc: 0.5023\n",
      "Epoch 40, Loss: 0.4539, Train Acc: 0.8308, Val Acc: 0.4995\n",
      "Epoch 50, Loss: 0.3937, Train Acc: 0.8791, Val Acc: 0.5061\n",
      "Epoch 60, Loss: 0.3374, Train Acc: 0.9178, Val Acc: 0.5042\n",
      "Epoch 70, Loss: 0.2779, Train Acc: 0.9487, Val Acc: 0.5070\n",
      "Epoch 80, Loss: 0.2196, Train Acc: 0.9721, Val Acc: 0.5089\n",
      "Epoch 90, Loss: 0.1784, Train Acc: 0.9854, Val Acc: 0.5070\n",
      "Epoch 100, Loss: 0.1518, Train Acc: 0.9918, Val Acc: 0.5033\n",
      "Epoch 110, Loss: 0.1319, Train Acc: 0.9950, Val Acc: 0.5051\n",
      "Epoch 120, Loss: 0.1193, Train Acc: 0.9964, Val Acc: 0.5108\n",
      "Epoch 130, Loss: 0.1071, Train Acc: 0.9986, Val Acc: 0.5070\n",
      "Epoch 140, Loss: 0.1013, Train Acc: 0.9980, Val Acc: 0.5005\n",
      "Epoch 150, Loss: 0.0957, Train Acc: 0.9982, Val Acc: 0.4977\n",
      "Epoch 160, Loss: 0.0856, Train Acc: 0.9988, Val Acc: 0.4958\n",
      "Epoch 170, Loss: 0.0812, Train Acc: 0.9986, Val Acc: 0.4958\n",
      "Epoch 180, Loss: 0.0778, Train Acc: 0.9992, Val Acc: 0.4949\n",
      "Epoch 190, Loss: 0.0733, Train Acc: 0.9992, Val Acc: 0.4949\n",
      "Test Accuracy: 0.5042\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import SAGEConv\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define the GraphSAGE model\n",
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(input_dim, hidden_dim)\n",
    "        self.conv2 = SAGEConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Initialize the model, optimizer, and loss function\n",
    "input_dim = data.x.shape[1]\n",
    "hidden_dim = 16\n",
    "output_dim = 2  # Binary classification (mature or not)\n",
    "model_sage = GraphSAGE(input_dim, hidden_dim, output_dim)\n",
    "optimizer = torch.optim.Adam(model_sage.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "# Training function\n",
    "def train():\n",
    "    model_sage.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model_sage(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(mask):\n",
    "    model_sage.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model_sage(data)\n",
    "        pred = out[mask].max(1)[1]\n",
    "        acc = (pred == data.y[mask]).sum().item() / mask.sum().item()\n",
    "    return acc\n",
    "\n",
    "# Train and evaluate the model\n",
    "for epoch in range(200):\n",
    "    loss = train()\n",
    "    if epoch % 10 == 0:\n",
    "        train_acc = evaluate(data.train_mask)\n",
    "        val_acc = evaluate(data.val_mask)\n",
    "        print(f'Epoch {epoch}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}')\n",
    "\n",
    "# Test the model\n",
    "test_acc = evaluate(data.test_mask)\n",
    "print(f'Test Accuracy: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.6909, Train Acc: 0.5457, Val Acc: 0.5463\n",
      "Epoch 10, Loss: 0.6496, Train Acc: 0.6494, Val Acc: 0.5388\n",
      "Epoch 20, Loss: 0.5893, Train Acc: 0.6830, Val Acc: 0.5304\n",
      "Epoch 30, Loss: 0.5285, Train Acc: 0.7386, Val Acc: 0.5220\n",
      "Epoch 40, Loss: 0.4700, Train Acc: 0.7813, Val Acc: 0.5220\n",
      "Epoch 50, Loss: 0.4078, Train Acc: 0.8186, Val Acc: 0.5285\n",
      "Epoch 60, Loss: 0.3622, Train Acc: 0.8338, Val Acc: 0.5313\n",
      "Epoch 70, Loss: 0.3038, Train Acc: 0.8843, Val Acc: 0.5164\n",
      "Epoch 80, Loss: 0.2491, Train Acc: 0.9242, Val Acc: 0.5061\n",
      "Epoch 90, Loss: 0.2148, Train Acc: 0.9202, Val Acc: 0.5145\n",
      "Epoch 100, Loss: 0.1718, Train Acc: 0.9531, Val Acc: 0.4864\n",
      "Epoch 110, Loss: 0.1479, Train Acc: 0.9667, Val Acc: 0.4911\n",
      "Epoch 120, Loss: 0.1388, Train Acc: 0.9629, Val Acc: 0.5061\n",
      "Epoch 130, Loss: 0.1166, Train Acc: 0.9769, Val Acc: 0.5023\n",
      "Epoch 140, Loss: 0.1062, Train Acc: 0.9798, Val Acc: 0.5108\n",
      "Epoch 150, Loss: 0.3417, Train Acc: 0.9493, Val Acc: 0.4780\n",
      "Epoch 160, Loss: 0.1039, Train Acc: 0.9641, Val Acc: 0.4808\n",
      "Epoch 170, Loss: 0.0899, Train Acc: 0.9737, Val Acc: 0.5070\n",
      "Epoch 180, Loss: 0.0830, Train Acc: 0.9878, Val Acc: 0.4977\n",
      "Epoch 190, Loss: 0.0763, Train Acc: 0.9890, Val Acc: 0.4995\n",
      "Test Accuracy: 0.4827\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import GATConv\n",
    "\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, heads=1):\n",
    "        super(GAT, self).__init__()\n",
    "        self.conv1 = GATConv(input_dim, hidden_dim, heads=heads, concat=True)\n",
    "        self.conv2 = GATConv(hidden_dim * heads, output_dim, heads=1, concat=False)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Initialize the model, optimizer, and train\n",
    "input_dim = data.x.shape[1]\n",
    "hidden_dim = 32\n",
    "output_dim = 2\n",
    "model_gat = GAT(input_dim, hidden_dim, output_dim, heads=4)\n",
    "optimizer = torch.optim.Adam(model_gat.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "\n",
    "# Training function\n",
    "def train():\n",
    "    model_gat.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model_gat(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(mask):\n",
    "    model_gat.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model_gat(data)\n",
    "        pred = out[mask].max(1)[1]\n",
    "        acc = (pred == data.y[mask]).sum().item() / mask.sum().item()\n",
    "    return acc\n",
    "\n",
    "# Train and evaluate the model\n",
    "for epoch in range(200):\n",
    "    loss = train()\n",
    "    if epoch % 10 == 0:\n",
    "        train_acc = evaluate(data.train_mask)\n",
    "        val_acc = evaluate(data.val_mask)\n",
    "        print(f'Epoch {epoch}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}')\n",
    "\n",
    "# Test the model\n",
    "test_acc = evaluate(data.test_mask)\n",
    "print(f'Test Accuracy: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
